<snippet>
<content><![CDATA[
${1:#aws_access_key = AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
#aws_secret_key = AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
#bucket = Bucket name.
#dest = The destination file path when downloading an object/key with a GET operation.
#ec2_url = Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints).  Ignored
#encrypt = When set for PUT mode, asks for server-side encryption
#expiration = Time limit (in seconds) for the URL generated and returned by S3/Walrus when performing a mode=put or
#headers = Custom headers for PUT operation, as a dictionary of 'key=value' and 'key=value,key=value'.
#marker = Specifies the key to start with when using list mode. Object keys are returned in alphabetical order, starting
#max_keys = Max number of results to return in list mode, set this if you want to retrieve fewer than the default 1000 keys.
#metadata = Metadata for PUT operation, as a dictionary of 'key=value' and 'key=value,key=value'.
#mode = Switches the module behaviour between put (upload), get (download), geturl (return download url (Ansible 1.3+),
#object = Keyname of the object inside the bucket. Can be used to create "virtual directories", see examples.
#overwrite = Force overwrite either locally on the filesystem or remotely with the object/key. Used with PUT and GET
#permission = This option let's the user set the canned permissions on the object/bucket that are created. The permissions
#prefix = Limits the response to keys that begin with the specified prefix for list mode
#profile = uses a boto profile. Only works with boto >= 2.24.0
#region = AWS region to create the bucket in. If not set then the value of the AWS_REGION and EC2_REGION environment
#retries = On recoverable failure, how many times to retry before actually failing.
#s3_url = S3 URL endpoint for usage with Eucalypus, fakes3, etc.  Otherwise assumes AWS
#security_token = AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
#src = The source file path when performing a PUT operation.
#validate_certs = When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
#version = Version ID of the object inside the bucket. Can be used to get a specific version of a file if versioning is
}- name: ${2:Name for s3 module.}
${3:  become: ${4:yes}}
  s3: ${5:aws_access_key=${6: } }${7:aws_secret_key=${8: } }${9:bucket=${10: } }${11:dest=${12: } }${13:ec2_url=${14: } }${15:encrypt=${16: } }${17:expiration=${18: } }${19:headers=${20: } }${21:marker=${22: } }${23:max_keys=${24: } }${25:metadata=${26: } }${27:mode=${28: } }${29:object=${30: } }${31:overwrite=${32: } }${33:permission=${34: } }${35:prefix=${36: } }${37:profile=${38: } }${39:region=${40: } }${41:retries=${42: } }${43:s3_url=${44: } }${45:security_token=${46: } }${47:src=${48: } }${49:validate_certs=${50: } }${51:version=${52: } }
${53:  when: ${54: variable is defined}}
${55:  with_items: ${56: array}}
]]></content>
	<tabTrigger>s3</tabTrigger>
	<scope>source.yaml,source.ansible</scope>
</snippet>
